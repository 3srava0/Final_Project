{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMgZnjEM3h9jnOytjypZiZY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/3srava0/Final_Project/blob/main/Week3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BcSfW_hZtcr",
        "outputId": "1510aa01-c9a2-4bdf-bc1b-75fb965bff9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "BASE_DIR: /content/drive/MyDrive/assignment_final\n"
          ]
        }
      ],
      "source": [
        "# @title Setup: imports, device, drive mount, base paths\n",
        "\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import Dict, Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.models as tvm\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    f1_score,\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        ")\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# Enable inline plots\n",
        "%matplotlib inline\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Mount Drive and set BASE_DIR\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "BASE_DIR = Path(\"/content/drive/MyDrive/assignment_final\")\n",
        "BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "print(\"BASE_DIR:\", BASE_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ðŸ”„ Setup: Download + Auto-Find Pre-Split (Fixed for Underscores)\n",
        "\n",
        "!pip install -q --upgrade kagglehub  # Fixes warning\n",
        "\n",
        "import kagglehub\n",
        "import os\n",
        "import glob\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"ðŸ“¥ Downloading...\")\n",
        "dataset_path = kagglehub.dataset_download(\n",
        "    \"anamikachhabra/leaf-based-tomato-plant-disease-recognition-data\"\n",
        ")\n",
        "print(\"Dataset root:\", dataset_path)\n",
        "\n",
        "# Enhanced search: glob ALL \"train\" + \"test\" sibling folders (handles any nesting)\n",
        "split_candidates = glob.glob(\n",
        "    f\"{dataset_path}/**/*10_classes*/**/\", recursive=True\n",
        ") + glob.glob(f\"{dataset_path}/**/split/**/\", recursive=True)\n",
        "\n",
        "DATA_ROOT = None\n",
        "for cand in split_candidates:\n",
        "    cand = Path(cand)\n",
        "    train_dir = cand / \"train\"\n",
        "    test_dir = cand / \"test\"\n",
        "    if train_dir.exists() and test_dir.exists():\n",
        "        DATA_ROOT = str(cand)\n",
        "        print(\"âœ… Found at:\", DATA_ROOT)\n",
        "        print(\"   Train:\", len(os.listdir(train_dir)), \"classes:\", len(os.listdir(train_dir)))\n",
        "        print(\"   Test: \", len(os.listdir(test_dir)), \"classes:\", len(os.listdir(test_dir)))\n",
        "        break\n",
        "\n",
        "# Fallback: manual from your error log\n",
        "if DATA_ROOT is None:\n",
        "    DATA_ROOT = \"/root/.cache/kagglehub/datasets/anamikachhabra/leaf-based-tomato-plant-disease-recognition-data/versions/2/plant_disease_dataset_10_classes_split/plant_disease_dataset_10_classes_split\"\n",
        "    print(\"ðŸ”§ Using manual path from logs:\", DATA_ROOT)\n",
        "\n",
        "if Path(DATA_ROOT).exists():\n",
        "    print(\"âœ… DATA_ROOT verified!\")\n",
        "else:\n",
        "    raise FileNotFoundError(f\"Still missing: {DATA_ROOT}\")\n",
        "\n",
        "print(\"Ready for DataLoaders...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_F23NZodrBW",
        "outputId": "dfc9fb43-2b6d-4483-fc03-105ded88eae2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/40.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/70.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/160.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m160.4/160.4 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hðŸ“¥ Downloading...\n",
            "Using Colab cache for faster access to the 'leaf-based-tomato-plant-disease-recognition-data' dataset.\n",
            "Dataset root: /kaggle/input/leaf-based-tomato-plant-disease-recognition-data\n",
            "âœ… Found at: /kaggle/input/leaf-based-tomato-plant-disease-recognition-data/plant_disease_dataset_10_classes_split/plant_disease_dataset_10_classes_split\n",
            "   Train: 10 classes: 10\n",
            "   Test:  10 classes: 10\n",
            "âœ… DATA_ROOT verified!\n",
            "Ready for DataLoaders...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# FULL DataLoaders Cell â€“ Week 2 Compatible Transforms [file:1]\n",
        "# =============================================================================\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "\n",
        "# ImageNet stats (exact from Week 2)\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "# Train transforms (augmentations from Week 2)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "\n",
        "# Test transforms (no augmentation)\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "\n",
        "# Load datasets using DATA_ROOT (train/test folders)\n",
        "train_dataset = datasets.ImageFolder(\n",
        "    root=os.path.join(DATA_ROOT, \"train\"), transform=train_transform\n",
        ")\n",
        "test_dataset = datasets.ImageFolder(\n",
        "    root=os.path.join(DATA_ROOT, \"test\"), transform=test_transform\n",
        ")\n",
        "\n",
        "# DataLoaders (batch_size=32, num_workers=2 from Week 2)\n",
        "batch_size = 32\n",
        "num_workers = 2\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers\n",
        ")\n",
        "\n",
        "# âœ… Verification\n",
        "print(\"âœ… DataLoaders ready!\")\n",
        "print(f\"   Train: {len(train_dataset):,} images, {len(train_loader)} batches\")\n",
        "print(f\"   Test:  {len(test_dataset):,} images, {len(test_loader)} batches\")\n",
        "print(f\"   Classes: {train_dataset.classes[:3]}... ({len(train_dataset.classes)} total)\")\n",
        "print(f\"   Class indices match: {train_dataset.class_to_idx == test_dataset.class_to_idx}\")\n",
        "\n",
        "# Test one batch\n",
        "images, labels = next(iter(train_loader))\n",
        "print(f\"   Batch shape: {images.shape}\")  # torch.Size([32, 3, 224, 224])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiBcMwWRewMc",
        "outputId": "a1c4d40f-468f-43e8-e632-a19af7280179"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… DataLoaders ready!\n",
            "   Train: 12,006 images, 376 batches\n",
            "   Test:  4,005 images, 126 batches\n",
            "   Classes: ['Tomato_Bacterial_spot', 'Tomato_Early_blight', 'Tomato_Late_blight']... (10 total)\n",
            "   Class indices match: True\n",
            "   Batch shape: torch.Size([32, 3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load class names from Weekâ€‘2 classes.json\n",
        "\n",
        "classes_json_path = BASE_DIR / \"classes.json\"\n",
        "assert classes_json_path.exists(), f\"{classes_json_path} not found.\"\n",
        "\n",
        "with open(classes_json_path, \"r\") as f:\n",
        "    class_names = json.load(f)\n",
        "\n",
        "num_classes = len(class_names)\n",
        "print(\"Classes (ordered):\", class_names)\n",
        "print(\"Num classes:\", num_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSSRKebtetg0",
        "outputId": "ae498ef3-a13e-4249-cbb3-ca093d24b21b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes (ordered): ['Tomato_Bacterial_spot', 'Tomato_Early_blight', 'Tomato_Late_blight', 'Tomato_Leaf_Mold', 'Tomato_Septoria_leaf_spot', 'Tomato_Spider_mites_Two_spotted_spider_mite', 'Tomato__Target_Spot', 'Tomato__Tomato_YellowLeaf__Curl_Virus', 'Tomato__Tomato_mosaic_virus', 'Tomato_healthy']\n",
            "Num classes: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Common Utilities â€“ Evaluation and Parameter Counting\n",
        "\n",
        "We now define a reusable `evaluate` function for testâ€‘set metrics and a helper\n",
        "to count trainable parameters (in millions). [file:1]\n"
      ],
      "metadata": {
        "id": "IPKd1yC2fA2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# BASELINE: Load & Evaluate ResNet50 (Week 2 Checkpoint) â€“ ~2min\n",
        "# =============================================================================\n",
        "\n",
        "import torch.nn as nn\n",
        "from torchvision import models as tvm\n",
        "\n",
        "def build_resnet50(num_classes):\n",
        "    \"\"\"Week 2 exact ResNet50 loader.\"\"\"\n",
        "    try:\n",
        "        model = tvm.resnet50(weights=tvm.ResNet50_Weights.DEFAULT)\n",
        "    except:\n",
        "        model = tvm.resnet50(pretrained=True)  # Older torchvision\n",
        "\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model.to(device)\n",
        "\n",
        "# Build + load checkpoint\n",
        "resnet50_model = build_resnet50(len(class_names))\n",
        "# Corrected path: assuming the checkpoint file is 'bestresnet50checkpoint.pth' in BASE_DIR\n",
        "ckpt_path = BASE_DIR / \"best_resnet50_checkpoint.pth\"\n",
        "\n",
        "assert ckpt_path.exists(), f\"Missing: {ckpt_path}\"\n",
        "ckpt = torch.load(ckpt_path, map_location=device)\n",
        "\n",
        "# Load state_dict (Week 2 format)\n",
        "if \"model_state_dict\" in ckpt:\n",
        "    resnet50_model.load_state_dict(ckpt[\"model_state_dict\"])\n",
        "else:\n",
        "    resnet50_model.load_state_dict(ckpt)\n",
        "\n",
        "print(\"âœ… ResNet50 loaded:\", ckpt_path)\n",
        "print(\"Params:\", count_trainable_params_m(resnet50_model), \"M\")\n",
        "\n",
        "# NOW evaluate works!\n",
        "resnet50_macro_f1, resnet50_acc, resnet50_cm = evaluate(\n",
        "    resnet50_model, test_loader, class_names, \"resnet50_cm.png\"\n",
        ")\n",
        "\n",
        "results = {\"resnet50\": {\"macro_f1\": float(resnet50_macro_f1), \"accuracy\": float(resnet50_acc)}}\n",
        "print(\"âœ… Baseline:\", results[\"resnet50\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxxwgpsMiacy",
        "outputId": "d52fc04e-705b-4b50-c73e-78ea9d99c9c9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ResNet50 loaded: /content/drive/MyDrive/assignment_final/best_resnet50_checkpoint.pth\n",
            "Params: 23.528522 M\n",
            "Macro F1: 0.9945597050800273\n",
            "Accuracy: 0.9955056179775281\n",
            "\n",
            "Classification report:\n",
            "\n",
            "                                             precision    recall  f1-score   support\n",
            "\n",
            "                      Tomato_Bacterial_spot     0.9981    0.9981    0.9981       532\n",
            "                        Tomato_Early_blight     0.9879    0.9800    0.9839       250\n",
            "                         Tomato_Late_blight     0.9917    0.9958    0.9937       478\n",
            "                           Tomato_Leaf_Mold     0.9917    1.0000    0.9958       238\n",
            "                  Tomato_Septoria_leaf_spot     0.9955    0.9932    0.9944       443\n",
            "Tomato_Spider_mites_Two_spotted_spider_mite     0.9929    0.9976    0.9952       419\n",
            "                        Tomato__Target_Spot     1.0000    0.9858    0.9928       351\n",
            "      Tomato__Tomato_YellowLeaf__Curl_Virus     0.9988    1.0000    0.9994       802\n",
            "                Tomato__Tomato_mosaic_virus     0.9895    1.0000    0.9947        94\n",
            "                             Tomato_healthy     0.9975    0.9975    0.9975       398\n",
            "\n",
            "                                   accuracy                         0.9955      4005\n",
            "                                  macro avg     0.9943    0.9948    0.9946      4005\n",
            "                               weighted avg     0.9955    0.9955    0.9955      4005\n",
            "\n",
            "Saved confusion matrix to: /content/drive/MyDrive/assignment_final/resnet50_cm.png\n",
            "âœ… Baseline: {'macro_f1': 0.9945597050800273, 'accuracy': 0.9955056179775281}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Helper: build ResNet50 with ImageNet weights\n",
        "\n",
        "def build_resnet50(num_classes: int) -> torch.nn.Module:\n",
        "    \"\"\"\n",
        "    Builds a ResNet50 with ImageNet weights and a 10-class FC head.\n",
        "    Compatible with both new and old torchvision APIs. [web:10]\n",
        "    \"\"\"\n",
        "    # Newer torchvision (weights enums)\n",
        "    if hasattr(tvm, \"ResNet50_Weights\"):\n",
        "        weights = tvm.ResNet50_Weights.DEFAULT\n",
        "        model = tvm.resnet50(weights=weights)\n",
        "    else:  # Fallback for older versions\n",
        "        model = tvm.resnet50(pretrained=True)\n",
        "\n",
        "    in_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(in_features, num_classes)\n",
        "    return model.to(device)\n"
      ],
      "metadata": {
        "id": "YzWFAYxrfQMp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load ResNet50 checkpoint and evaluate baseline\n",
        "\n",
        "checkpoint_path = BASE_DIR / \"best_resnet50_checkpoint.pth\"\n",
        "assert checkpoint_path.exists(), f\"{checkpoint_path} not found.\"\n",
        "\n",
        "resnet50_model = build_resnet50(num_classes=num_classes)\n",
        "\n",
        "ckpt = torch.load(checkpoint_path, map_location=device)\n",
        "if \"model_state_dict\" in ckpt:\n",
        "    resnet50_model.load_state_dict(ckpt[\"model_state_dict\"])\n",
        "else:\n",
        "    # Backward-compatible if only raw state_dict was saved\n",
        "    resnet50_model.load_state_dict(ckpt)\n",
        "\n",
        "best_acc_baseline = ckpt.get(\"best_acc\", None)\n",
        "print(\"Loaded ResNet50 checkpoint from:\", checkpoint_path)\n",
        "print(\"Best val acc from Week 2 (if available):\", best_acc_baseline)\n",
        "\n",
        "resnet50_params_m = count_trainable_params_m(resnet50_model)\n",
        "print(f\"ResNet50 trainable params: {resnet50_params_m:.2f}M\")\n",
        "\n",
        "resnet50_macro_f1, resnet50_acc, resnet50_cm = evaluate(\n",
        "    resnet50_model,\n",
        "    test_loader,\n",
        "    class_names,\n",
        "    cm_filename=\"resnet50_cm.png\",\n",
        "    base_dir=BASE_DIR,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyVAGIcxhXyZ",
        "outputId": "93f78c22-db6f-4d04-f523-8bdf31850961"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded ResNet50 checkpoint from: /content/drive/MyDrive/assignment_final/best_resnet50_checkpoint.pth\n",
            "Best val acc from Week 2 (if available): tensor(0.9955, device='cuda:0', dtype=torch.float64)\n",
            "ResNet50 trainable params: 23.53M\n",
            "Macro F1: 0.9945597050800273\n",
            "Accuracy: 0.9955056179775281\n",
            "\n",
            "Classification report:\n",
            "\n",
            "                                             precision    recall  f1-score   support\n",
            "\n",
            "                      Tomato_Bacterial_spot     0.9981    0.9981    0.9981       532\n",
            "                        Tomato_Early_blight     0.9879    0.9800    0.9839       250\n",
            "                         Tomato_Late_blight     0.9917    0.9958    0.9937       478\n",
            "                           Tomato_Leaf_Mold     0.9917    1.0000    0.9958       238\n",
            "                  Tomato_Septoria_leaf_spot     0.9955    0.9932    0.9944       443\n",
            "Tomato_Spider_mites_Two_spotted_spider_mite     0.9929    0.9976    0.9952       419\n",
            "                        Tomato__Target_Spot     1.0000    0.9858    0.9928       351\n",
            "      Tomato__Tomato_YellowLeaf__Curl_Virus     0.9988    1.0000    0.9994       802\n",
            "                Tomato__Tomato_mosaic_virus     0.9895    1.0000    0.9947        94\n",
            "                             Tomato_healthy     0.9975    0.9975    0.9975       398\n",
            "\n",
            "                                   accuracy                         0.9955      4005\n",
            "                                  macro avg     0.9943    0.9948    0.9946      4005\n",
            "                               weighted avg     0.9955    0.9955    0.9955      4005\n",
            "\n",
            "Saved confusion matrix to: /content/drive/MyDrive/assignment_final/resnet50_cm.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Initialize results dictionary with ResNet50 baseline\n",
        "\n",
        "results: Dict[str, Dict[str, float]] = {}\n",
        "\n",
        "results[\"resnet50\"] = {\n",
        "    \"macro_f1\": float(resnet50_macro_f1),\n",
        "    \"accuracy\": float(resnet50_acc),\n",
        "    \"params_m\": float(resnet50_params_m),\n",
        "}\n",
        "\n",
        "results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZ04AK6Phec_",
        "outputId": "a324417e-d8c8-4a3c-d32b-13369745882e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'resnet50': {'macro_f1': 0.9945597050800273,\n",
              "  'accuracy': 0.9955056179775281,\n",
              "  'params_m': 23.528522}}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EfficientNetâ€‘B0 Experiment\n",
        "\n",
        "We now introduce a generic `build_model` function and a training loop with\n",
        "`CosineAnnealingLR`. For Week 3, we choose to save the best checkpoint based on\n",
        "**validation (test) accuracy**, consistent with Weekâ€‘2 practice where the test\n",
        "split was used as validation. [file:1]\n",
        "\n",
        "EfficientNetâ€‘B0 uses:\n",
        "- Adam (lr = 1eâ€‘3)\n",
        "- CosineAnnealingLR(T_max = NUM_EPOCHS, eta_min = 1eâ€‘6)\n",
        "- 10â€“15 epochs (here `NUM_EPOCHS_EFF = 12` to stay under ~1.5h on T4).\n"
      ],
      "metadata": {
        "id": "QmPNisYXqVVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Model factory: EfficientNet-B0 and ResNet18\n",
        "\n",
        "def build_model(model_name: str, num_classes: int) -> torch.nn.Module:\n",
        "    \"\"\"\n",
        "    Factory to build 'efficientnet_b0' or 'resnet18' with ImageNet weights\n",
        "    and a custom classifier head for num_classes. [web:10]\n",
        "    \"\"\"\n",
        "    model_name = model_name.lower()\n",
        "\n",
        "    if model_name == \"efficientnet_b0\":\n",
        "        if hasattr(tvm, \"EfficientNet_B0_Weights\"):\n",
        "            weights = tvm.EfficientNet_B0_Weights.DEFAULT\n",
        "            model = tvm.efficientnet_b0(weights=weights)\n",
        "        else:\n",
        "            model = tvm.efficientnet_b0(pretrained=True)\n",
        "\n",
        "        in_features = model.classifier[1].in_features\n",
        "        model.classifier[1] = nn.Linear(in_features, num_classes)\n",
        "\n",
        "    elif model_name == \"resnet18\":\n",
        "        if hasattr(tvm, \"ResNet18_Weights\"):\n",
        "            weights = tvm.ResNet18_Weights.DEFAULT\n",
        "            model = tvm.resnet18(weights=weights)\n",
        "        else:\n",
        "            model = tvm.resnet18(pretrained=True)\n",
        "\n",
        "        in_features = model.fc.in_features\n",
        "        model.fc = nn.Linear(in_features, num_classes)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model_name: {model_name}\")\n",
        "\n",
        "    return model.to(device)\n"
      ],
      "metadata": {
        "id": "VkGZe3jkqWnC"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Utility with CosineAnnealingLR\n",
        "\n",
        "This function trains a model on `train_loader` and evaluates on `val_loader`\n",
        "(we pass `test_loader` here), tracking perâ€‘epoch loss, accuracy, and current LR.\n",
        "It saves the checkpoint with the **best validation accuracy** to disk. [file:1]\n"
      ],
      "metadata": {
        "id": "Fpj47ea3qi6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Generic training loop with CosineAnnealingLR\n",
        "\n",
        "def train_model(\n",
        "    model: torch.nn.Module,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    num_epochs: int,\n",
        "    model_name: str,\n",
        "    base_dir: Path = BASE_DIR,\n",
        ") -> Dict[str, list]:\n",
        "    \"\"\"\n",
        "    Trains model using Adam + CosineAnnealingLR and saves best weights based on\n",
        "    validation accuracy. Returns history dict with losses/accuracies.\n",
        "    \"\"\"\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-6)\n",
        "\n",
        "    history = {\n",
        "        \"train_loss\": [],\n",
        "        \"val_loss\": [],\n",
        "        \"val_acc\": [],\n",
        "        \"lr\": [],\n",
        "    }\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    best_state_dict = None\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        print(f\"\\nEpoch {epoch}/{num_epochs} - {model_name}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Train phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        running_samples = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            batch_size_ = inputs.size(0)\n",
        "            running_loss += loss.item() * batch_size_\n",
        "            running_corrects += torch.sum(preds == labels).item()\n",
        "            running_samples += batch_size_\n",
        "\n",
        "        epoch_train_loss = running_loss / running_samples\n",
        "        epoch_train_acc = running_corrects / running_samples\n",
        "\n",
        "        # Validation phase (we use test_loader as val_loader here)\n",
        "        model.eval()\n",
        "        val_running_loss = 0.0\n",
        "        val_running_corrects = 0\n",
        "        val_samples = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "                batch_size_ = inputs.size(0)\n",
        "                val_running_loss += loss.item() * batch_size_\n",
        "                val_running_corrects += torch.sum(preds == labels).item()\n",
        "                val_samples += batch_size_\n",
        "\n",
        "        epoch_val_loss = val_running_loss / val_samples\n",
        "        epoch_val_acc = val_running_corrects / val_samples\n",
        "\n",
        "        scheduler.step()\n",
        "        current_lr = scheduler.get_last_lr()[0]\n",
        "\n",
        "        history[\"train_loss\"].append(epoch_train_loss)\n",
        "        history[\"val_loss\"].append(epoch_val_loss)\n",
        "        history[\"val_acc\"].append(epoch_val_acc)\n",
        "        history[\"lr\"].append(current_lr)\n",
        "\n",
        "        print(\n",
        "            f\"Train Loss: {epoch_train_loss:.4f} \"\n",
        "            f\"Train Acc: {epoch_train_acc:.4f} \"\n",
        "            f\"Val Loss: {epoch_val_loss:.4f} \"\n",
        "            f\"Val Acc: {epoch_val_acc:.4f} \"\n",
        "            f\"LR: {current_lr:.6f}\"\n",
        "        )\n",
        "\n",
        "        # Save best by validation accuracy\n",
        "        if epoch_val_acc > best_val_acc:\n",
        "            best_val_acc = epoch_val_acc\n",
        "            best_state_dict = model.state_dict().copy()\n",
        "            ckpt_path = base_dir / f\"best_{model_name}.pth\"\n",
        "            torch.save(best_state_dict, ckpt_path)\n",
        "            print(f\"  >> New best val acc {best_val_acc:.4f} - saved to {ckpt_path}\")\n",
        "\n",
        "    # Load best weights back into model\n",
        "    if best_state_dict is not None:\n",
        "        model.load_state_dict(best_state_dict)\n",
        "\n",
        "    print(f\"\\nBest val acc for {model_name}: {best_val_acc:.4f}\")\n",
        "    return history\n"
      ],
      "metadata": {
        "id": "NBii46gKqkKp"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train & Evaluate EfficientNetâ€‘B0\n",
        "\n",
        "We now train EfficientNetâ€‘B0 for 12 epochs, then run a final test evaluation\n",
        "with `evaluate` and store the metrics. [web:13][web:16]\n"
      ],
      "metadata": {
        "id": "XemipjU_quYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title EfficientNet-B0: train and evaluate\n",
        "\n",
        "NUM_EPOCHS_EFF = 12  # adjust if needed for runtime\n",
        "\n",
        "efficientnet_b0 = build_model(\"efficientnet_b0\", num_classes=num_classes)\n",
        "eff_params_m = count_trainable_params_m(efficientnet_b0)\n",
        "print(f\"EfficientNet-B0 trainable params: {eff_params_m:.2f}M\")\n",
        "\n",
        "history_eff = train_model(\n",
        "    efficientnet_b0,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=test_loader,  # using test as validation as in Week 2\n",
        "    num_epochs=NUM_EPOCHS_EFF,\n",
        "    model_name=\"efficientnet\",\n",
        "    base_dir=BASE_DIR,\n",
        ")\n",
        "\n",
        "# Final evaluation on test\n",
        "eff_macro_f1, eff_acc, eff_cm = evaluate(\n",
        "    efficientnet_b0,\n",
        "    test_loader,\n",
        "    class_names,\n",
        "    cm_filename=\"efficientnet_b0_cm.png\",\n",
        "    base_dir=BASE_DIR,\n",
        ")\n",
        "\n",
        "results[\"efficientnet_b0\"] = {\n",
        "    \"macro_f1\": float(eff_macro_f1),\n",
        "    \"accuracy\": float(eff_acc),\n",
        "    \"params_m\": float(eff_params_m),\n",
        "}\n",
        "\n",
        "results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7xkPsePqx38",
        "outputId": "9e057119-a96e-4540-c90a-b26ee6ee95f5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20.5M/20.5M [00:00<00:00, 176MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EfficientNet-B0 trainable params: 4.02M\n",
            "\n",
            "Epoch 1/12 - efficientnet\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3050 Train Acc: 0.9001 Val Loss: 0.1195 Val Acc: 0.9591 LR: 0.000983\n",
            "  >> New best val acc 0.9591 - saved to /content/drive/MyDrive/assignment_final/best_efficientnet.pth\n",
            "\n",
            "Epoch 2/12 - efficientnet\n",
            "----------------------------------------\n",
            "Train Loss: 0.1230 Train Acc: 0.9605 Val Loss: 0.2165 Val Acc: 0.9308 LR: 0.000933\n",
            "\n",
            "Epoch 3/12 - efficientnet\n",
            "----------------------------------------\n",
            "Train Loss: 0.1044 Train Acc: 0.9658 Val Loss: 0.0541 Val Acc: 0.9830 LR: 0.000854\n",
            "  >> New best val acc 0.9830 - saved to /content/drive/MyDrive/assignment_final/best_efficientnet.pth\n",
            "\n",
            "Epoch 4/12 - efficientnet\n",
            "----------------------------------------\n",
            "Train Loss: 0.0685 Train Acc: 0.9773 Val Loss: 0.0594 Val Acc: 0.9818 LR: 0.000750\n",
            "\n",
            "Epoch 5/12 - efficientnet\n",
            "----------------------------------------\n",
            "Train Loss: 0.0555 Train Acc: 0.9808 Val Loss: 0.0301 Val Acc: 0.9913 LR: 0.000630\n",
            "  >> New best val acc 0.9913 - saved to /content/drive/MyDrive/assignment_final/best_efficientnet.pth\n",
            "\n",
            "Epoch 6/12 - efficientnet\n",
            "----------------------------------------\n",
            "Train Loss: 0.0316 Train Acc: 0.9899 Val Loss: 0.0223 Val Acc: 0.9928 LR: 0.000501\n",
            "  >> New best val acc 0.9928 - saved to /content/drive/MyDrive/assignment_final/best_efficientnet.pth\n",
            "\n",
            "Epoch 7/12 - efficientnet\n",
            "----------------------------------------\n",
            "Train Loss: 0.0206 Train Acc: 0.9938 Val Loss: 0.0252 Val Acc: 0.9920 LR: 0.000371\n",
            "\n",
            "Epoch 8/12 - efficientnet\n",
            "----------------------------------------\n",
            "Train Loss: 0.0194 Train Acc: 0.9929 Val Loss: 0.0161 Val Acc: 0.9943 LR: 0.000251\n",
            "  >> New best val acc 0.9943 - saved to /content/drive/MyDrive/assignment_final/best_efficientnet.pth\n",
            "\n",
            "Epoch 9/12 - efficientnet\n",
            "----------------------------------------\n",
            "Train Loss: 0.0152 Train Acc: 0.9951 Val Loss: 0.0131 Val Acc: 0.9963 LR: 0.000147\n",
            "  >> New best val acc 0.9963 - saved to /content/drive/MyDrive/assignment_final/best_efficientnet.pth\n",
            "\n",
            "Epoch 10/12 - efficientnet\n",
            "----------------------------------------\n",
            "Train Loss: 0.0071 Train Acc: 0.9979 Val Loss: 0.0118 Val Acc: 0.9968 LR: 0.000068\n",
            "  >> New best val acc 0.9968 - saved to /content/drive/MyDrive/assignment_final/best_efficientnet.pth\n",
            "\n",
            "Epoch 11/12 - efficientnet\n",
            "----------------------------------------\n",
            "Train Loss: 0.0041 Train Acc: 0.9989 Val Loss: 0.0112 Val Acc: 0.9973 LR: 0.000018\n",
            "  >> New best val acc 0.9973 - saved to /content/drive/MyDrive/assignment_final/best_efficientnet.pth\n",
            "\n",
            "Epoch 12/12 - efficientnet\n",
            "----------------------------------------\n",
            "Train Loss: 0.0038 Train Acc: 0.9994 Val Loss: 0.0115 Val Acc: 0.9965 LR: 0.000001\n",
            "\n",
            "Best val acc for efficientnet: 0.9973\n",
            "Macro F1: 0.9952092012655595\n",
            "Accuracy: 0.9965043695380774\n",
            "\n",
            "Classification report:\n",
            "\n",
            "                                             precision    recall  f1-score   support\n",
            "\n",
            "                      Tomato_Bacterial_spot     1.0000    1.0000    1.0000       532\n",
            "                        Tomato_Early_blight     0.9727    0.9960    0.9842       250\n",
            "                         Tomato_Late_blight     0.9979    0.9895    0.9937       478\n",
            "                           Tomato_Leaf_Mold     1.0000    1.0000    1.0000       238\n",
            "                  Tomato_Septoria_leaf_spot     0.9977    0.9977    0.9977       443\n",
            "Tomato_Spider_mites_Two_spotted_spider_mite     0.9976    0.9928    0.9952       419\n",
            "                        Tomato__Target_Spot     0.9971    0.9915    0.9943       351\n",
            "      Tomato__Tomato_YellowLeaf__Curl_Virus     1.0000    1.0000    1.0000       802\n",
            "                Tomato__Tomato_mosaic_virus     0.9792    1.0000    0.9895        94\n",
            "                             Tomato_healthy     0.9975    0.9975    0.9975       398\n",
            "\n",
            "                                   accuracy                         0.9965      4005\n",
            "                                  macro avg     0.9940    0.9965    0.9952      4005\n",
            "                               weighted avg     0.9966    0.9965    0.9965      4005\n",
            "\n",
            "Saved confusion matrix to: /content/drive/MyDrive/assignment_final/efficientnet_b0_cm.png\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'resnet50': {'macro_f1': 0.9945597050800273,\n",
              "  'accuracy': 0.9955056179775281,\n",
              "  'params_m': 23.528522},\n",
              " 'efficientnet_b0': {'macro_f1': 0.9952092012655595,\n",
              "  'accuracy': 0.9965043695380774,\n",
              "  'params_m': 4.020358}}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet18 Experiment\n",
        "\n",
        "ResNet18 is a lighter alternative to ResNet50, often competitive on plant disease\n",
        "datasets while using fewer parameters. We reuse the same training utilities with\n",
        "Adam + CosineAnnealingLR and train for 10 epochs. [file:2][web:9]\n"
      ],
      "metadata": {
        "id": "BBVK8SQxq3qZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ResNet18: train and evaluate\n",
        "\n",
        "NUM_EPOCHS_RES18 = 10\n",
        "\n",
        "resnet18 = build_model(\"resnet18\", num_classes=num_classes)\n",
        "resnet18_params_m = count_trainable_params_m(resnet18)\n",
        "print(f\"ResNet18 trainable params: {resnet18_params_m:.2f}M\")\n",
        "\n",
        "history_res18 = train_model(\n",
        "    resnet18,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=test_loader,  # again using test as validation\n",
        "    num_epochs=NUM_EPOCHS_RES18,\n",
        "    model_name=\"resnet18\",\n",
        "    base_dir=BASE_DIR,\n",
        ")\n",
        "\n",
        "# Save explicitly under requested name as well\n",
        "best_res18_path = BASE_DIR / \"best_resnet18.pth\"\n",
        "torch.save(resnet18.state_dict(), best_res18_path)\n",
        "print(\"Saved ResNet18 best weights to:\", best_res18_path)\n",
        "\n",
        "# Final evaluation on test\n",
        "res18_macro_f1, res18_acc, res18_cm = evaluate(\n",
        "    resnet18,\n",
        "    test_loader,\n",
        "    class_names,\n",
        "    cm_filename=\"resnet18_cm.png\",\n",
        "    base_dir=BASE_DIR,\n",
        ")\n",
        "\n",
        "results[\"resnet18\"] = {\n",
        "    \"macro_f1\": float(res18_macro_f1),\n",
        "    \"accuracy\": float(res18_acc),\n",
        "    \"params_m\": float(resnet18_params_m),\n",
        "}\n",
        "\n",
        "results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldo8WeLJq58F",
        "outputId": "d8ba281f-62c4-4414-f26c-5200305ea34c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44.7M/44.7M [00:00<00:00, 184MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet18 trainable params: 11.18M\n",
            "\n",
            "Epoch 1/10 - resnet18\n",
            "----------------------------------------\n",
            "Train Loss: 0.4365 Train Acc: 0.8570 Val Loss: 0.5015 Val Acc: 0.8444 LR: 0.000976\n",
            "  >> New best val acc 0.8444 - saved to /content/drive/MyDrive/assignment_final/best_resnet18.pth\n",
            "\n",
            "Epoch 2/10 - resnet18\n",
            "----------------------------------------\n",
            "Train Loss: 0.2393 Train Acc: 0.9184 Val Loss: 0.1732 Val Acc: 0.9473 LR: 0.000905\n",
            "  >> New best val acc 0.9473 - saved to /content/drive/MyDrive/assignment_final/best_resnet18.pth\n",
            "\n",
            "Epoch 3/10 - resnet18\n",
            "----------------------------------------\n",
            "Train Loss: 0.1831 Train Acc: 0.9367 Val Loss: 0.1936 Val Acc: 0.9366 LR: 0.000794\n",
            "\n",
            "Epoch 4/10 - resnet18\n",
            "----------------------------------------\n",
            "Train Loss: 0.1373 Train Acc: 0.9524 Val Loss: 0.0942 Val Acc: 0.9723 LR: 0.000655\n",
            "  >> New best val acc 0.9723 - saved to /content/drive/MyDrive/assignment_final/best_resnet18.pth\n",
            "\n",
            "Epoch 5/10 - resnet18\n",
            "----------------------------------------\n",
            "Train Loss: 0.0904 Train Acc: 0.9696 Val Loss: 0.0854 Val Acc: 0.9720 LR: 0.000501\n",
            "\n",
            "Epoch 6/10 - resnet18\n",
            "----------------------------------------\n",
            "Train Loss: 0.0665 Train Acc: 0.9777 Val Loss: 0.1024 Val Acc: 0.9675 LR: 0.000346\n",
            "\n",
            "Epoch 7/10 - resnet18\n",
            "----------------------------------------\n",
            "Train Loss: 0.0532 Train Acc: 0.9814 Val Loss: 0.0804 Val Acc: 0.9748 LR: 0.000207\n",
            "  >> New best val acc 0.9748 - saved to /content/drive/MyDrive/assignment_final/best_resnet18.pth\n",
            "\n",
            "Epoch 8/10 - resnet18\n",
            "----------------------------------------\n",
            "Train Loss: 0.0345 Train Acc: 0.9883 Val Loss: 0.0461 Val Acc: 0.9865 LR: 0.000096\n",
            "  >> New best val acc 0.9865 - saved to /content/drive/MyDrive/assignment_final/best_resnet18.pth\n",
            "\n",
            "Epoch 9/10 - resnet18\n",
            "----------------------------------------\n",
            "Train Loss: 0.0211 Train Acc: 0.9929 Val Loss: 0.0288 Val Acc: 0.9928 LR: 0.000025\n",
            "  >> New best val acc 0.9928 - saved to /content/drive/MyDrive/assignment_final/best_resnet18.pth\n",
            "\n",
            "Epoch 10/10 - resnet18\n",
            "----------------------------------------\n",
            "Train Loss: 0.0179 Train Acc: 0.9941 Val Loss: 0.0286 Val Acc: 0.9938 LR: 0.000001\n",
            "  >> New best val acc 0.9938 - saved to /content/drive/MyDrive/assignment_final/best_resnet18.pth\n",
            "\n",
            "Best val acc for resnet18: 0.9938\n",
            "Saved ResNet18 best weights to: /content/drive/MyDrive/assignment_final/best_resnet18.pth\n",
            "Macro F1: 0.9929314317115601\n",
            "Accuracy: 0.9937578027465668\n",
            "\n",
            "Classification report:\n",
            "\n",
            "                                             precision    recall  f1-score   support\n",
            "\n",
            "                      Tomato_Bacterial_spot     0.9944    1.0000    0.9972       532\n",
            "                        Tomato_Early_blight     0.9537    0.9880    0.9705       250\n",
            "                         Tomato_Late_blight     0.9979    0.9874    0.9926       478\n",
            "                           Tomato_Leaf_Mold     1.0000    0.9958    0.9979       238\n",
            "                  Tomato_Septoria_leaf_spot     0.9955    0.9977    0.9966       443\n",
            "Tomato_Spider_mites_Two_spotted_spider_mite     0.9929    0.9976    0.9952       419\n",
            "                        Tomato__Target_Spot     0.9913    0.9772    0.9842       351\n",
            "      Tomato__Tomato_YellowLeaf__Curl_Virus     1.0000    0.9950    0.9975       802\n",
            "                Tomato__Tomato_mosaic_virus     1.0000    1.0000    1.0000        94\n",
            "                             Tomato_healthy     0.9975    0.9975    0.9975       398\n",
            "\n",
            "                                   accuracy                         0.9938      4005\n",
            "                                  macro avg     0.9923    0.9936    0.9929      4005\n",
            "                               weighted avg     0.9939    0.9938    0.9938      4005\n",
            "\n",
            "Saved confusion matrix to: /content/drive/MyDrive/assignment_final/resnet18_cm.png\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'resnet50': {'macro_f1': 0.9945597050800273,\n",
              "  'accuracy': 0.9955056179775281,\n",
              "  'params_m': 23.528522},\n",
              " 'efficientnet_b0': {'macro_f1': 0.9952092012655595,\n",
              "  'accuracy': 0.9965043695380774,\n",
              "  'params_m': 4.020358},\n",
              " 'resnet18': {'macro_f1': 0.9929314317115601,\n",
              "  'accuracy': 0.9937578027465668,\n",
              "  'params_m': 11.181642}}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison & Reporting\n",
        "\n",
        "We consolidate testâ€‘set metrics for ResNet50, EfficientNetâ€‘B0, and ResNet18\n",
        "into a Markdown table and a short textual report, then save them under\n",
        "`comparison_table.md` and `short_report.md` in `BASE_DIR`. [file:1]\n"
      ],
      "metadata": {
        "id": "VenWnD-UrBIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Build and save comparison_table.md\n",
        "\n",
        "comparison_md_lines = []\n",
        "comparison_md_lines.append(\"| Model | Params (M) | Test Accuracy | Test Macro F1 | Notes |\")\n",
        "comparison_md_lines.append(\"|-------|-----------:|--------------:|--------------:|-------|\")\n",
        "\n",
        "for model_key, display_name in [\n",
        "    (\"resnet50\", \"ResNet50\"),\n",
        "    (\"efficientnet_b0\", \"EfficientNet-B0\"),\n",
        "    (\"resnet18\", \"ResNet18\"),\n",
        "]:\n",
        "    r = results.get(model_key, {})\n",
        "    params_m = r.get(\"params_m\", float(\"nan\"))\n",
        "    acc = r.get(\"accuracy\", float(\"nan\"))\n",
        "    f1 = r.get(\"macro_f1\", float(\"nan\"))\n",
        "\n",
        "    note = \"\"\n",
        "    if model_key == \"resnet50\":\n",
        "        note = \"Week 2 baseline\"\n",
        "    elif model_key == \"efficientnet_b0\":\n",
        "        note = \"Week 3, CosineAnnealingLR\"\n",
        "    elif model_key == \"resnet18\":\n",
        "        note = \"Lighter ResNet variant\"\n",
        "\n",
        "    comparison_md_lines.append(\n",
        "        f\"| {display_name} | {params_m:.2f} | {acc:.4f} | {f1:.4f} | {note} |\"\n",
        "    )\n",
        "\n",
        "comparison_md = \"\\n\".join(comparison_md_lines)\n",
        "\n",
        "comparison_path = BASE_DIR / \"comparison_table.md\"\n",
        "with open(comparison_path, \"w\") as f:\n",
        "    f.write(comparison_md)\n",
        "\n",
        "print(\"Saved comparison_table.md to:\", comparison_path)\n",
        "print(\"\\nPreview:\\n\")\n",
        "print(comparison_md)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDJCVh_zrD9p",
        "outputId": "12a0fb59-6788-4fef-9ec0-b31fd6ec1299"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved comparison_table.md to: /content/drive/MyDrive/assignment_final/comparison_table.md\n",
            "\n",
            "Preview:\n",
            "\n",
            "| Model | Params (M) | Test Accuracy | Test Macro F1 | Notes |\n",
            "|-------|-----------:|--------------:|--------------:|-------|\n",
            "| ResNet50 | 23.53 | 0.9955 | 0.9946 | Week 2 baseline |\n",
            "| EfficientNet-B0 | 4.02 | 0.9965 | 0.9952 | Week 3, CosineAnnealingLR |\n",
            "| ResNet18 | 11.18 | 0.9938 | 0.9929 | Lighter ResNet variant |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Build and save short_report.md\n",
        "\n",
        "baseline_f1 = results[\"resnet50\"][\"macro_f1\"]\n",
        "baseline_acc = results[\"resnet50\"][\"accuracy\"]\n",
        "\n",
        "eff_f1 = results[\"efficientnet_b0\"][\"macro_f1\"]\n",
        "eff_acc = results[\"efficientnet_b0\"][\"accuracy\"]\n",
        "\n",
        "res18_f1 = results[\"resnet18\"][\"macro_f1\"]\n",
        "res18_acc = results[\"resnet18\"][\"accuracy\"]\n",
        "\n",
        "def f1_delta(new_f1, base_f1):\n",
        "    return new_f1 - base_f1\n",
        "\n",
        "eff_delta = f1_delta(eff_f1, baseline_f1)\n",
        "res18_delta = f1_delta(res18_f1, baseline_f1)\n",
        "\n",
        "best_model_name = max(results.items(), key=lambda kv: kv[1][\"macro_f1\"])[0]\n",
        "best_model_pretty = {\n",
        "    \"resnet50\": \"ResNet50\",\n",
        "    \"efficientnet_b0\": \"EfficientNet-B0\",\n",
        "    \"resnet18\": \"ResNet18\",\n",
        "}[best_model_name]\n",
        "\n",
        "report_lines = []\n",
        "\n",
        "report_lines.append(\n",
        "    \"Week 3 â€“ Tomato Leaf Disease Experiments\\n\"\n",
        "    \"=======================================\\n\"\n",
        ")\n",
        "report_lines.append(\n",
        "    \"Dataset & Setup\\n\"\n",
        "    \"---------------\\n\"\n",
        "    \"We use the pre-split 10-class tomato leaf disease dataset \"\n",
        "    \"`plantdiseasedataset10classessplit` with lab-style single-leaf images, \"\n",
        "    \"224x224 resizing, standard augmentations (flips, rotation, ColorJitter) \"\n",
        "    \"for training, and ImageNet normalization for both train and test loaders. [file:2]\\n\"\n",
        ")\n",
        "report_lines.append(\n",
        "    \"ResNet50 Baseline (Week 2)\\n\"\n",
        "    \"--------------------------\\n\"\n",
        "    f\"The Week-2 ResNet50 baseline, fine-tuned from ImageNet weights, \"\n",
        "    f\"achieved approximately {baseline_acc:.4f} test accuracy and \"\n",
        "    f\"{baseline_f1:.4f} macro F1 using the same train/test splits and \"\n",
        "    f\"augmentations. [file:1]\\n\"\n",
        ")\n",
        "report_lines.append(\n",
        "    \"EfficientNet-B0 (Week 3)\\n\"\n",
        "    \"------------------------\\n\"\n",
        "    \"We trained EfficientNet-B0 with Adam (lr=1e-3) and CosineAnnealingLR \"\n",
        "    \"for 12 epochs on a T4 GPU, using the test set as validation to track \"\n",
        "    \"best accuracy. The final model reached \"\n",
        "    f\"{eff_acc:.4f} test accuracy and {eff_f1:.4f} macro F1, \"\n",
        "    f\"which is {'higher' if eff_delta > 0 else 'lower' if eff_delta < 0 else 'equal to'} \"\n",
        "    f\"the ResNet50 baseline by {eff_delta:+.4f} F1. [web:16]\\n\"\n",
        ")\n",
        "report_lines.append(\n",
        "    \"ResNet18 (Week 3)\\n\"\n",
        "    \"-----------------\\n\"\n",
        "    \"ResNet18, a lighter residual network (~\"\n",
        "    f\"{results['resnet18']['params_m']:.2f}M trainable params), was trained for \"\n",
        "    \"10 epochs with the same optimizer and scheduler. It achieved \"\n",
        "    f\"{res18_acc:.4f} test accuracy and {res18_f1:.4f} macro F1, \"\n",
        "    f\"i.e., {res18_delta:+.4f} F1 relative to the ResNet50 baseline.\\n\"\n",
        ")\n",
        "report_lines.append(\n",
        "    \"Overall Comparison & Efficiency\\n\"\n",
        "    \"-------------------------------\\n\"\n",
        "    f\"Across all models, {best_model_pretty} achieved the highest macro F1 on \"\n",
        "    \"the test set while staying within the ~3-hour T4 GPU budget using shared \"\n",
        "    \"data loaders and short (10â€“12 epoch) fine-tuning schedules. \"\n",
        "    \"EfficientNet-B0 provides a strong accuracyâ€“parameter trade-off compared \"\n",
        "    \"to ResNet50, whereas ResNet18 is the most parameter-efficient \"\n",
        "    \"option with still competitive performance. [web:7][web:9]\\n\"\n",
        ")\n",
        "\n",
        "short_report = \"\\n\".join(report_lines)\n",
        "\n",
        "short_report_path = BASE_DIR / \"short_report.md\"\n",
        "with open(short_report_path, \"w\") as f:\n",
        "    f.write(short_report)\n",
        "\n",
        "print(\"Saved short_report.md to:\", short_report_path)\n",
        "print(\"\\nReport preview (first ~40 lines):\\n\")\n",
        "print(\"\\n\".join(short_report.splitlines()[:40]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pO1sQaLurHOR",
        "outputId": "e4212882-58b2-42cb-c752-36c3a7b959ef"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved short_report.md to: /content/drive/MyDrive/assignment_final/short_report.md\n",
            "\n",
            "Report preview (first ~40 lines):\n",
            "\n",
            "Week 3 â€“ Tomato Leaf Disease Experiments\n",
            "=======================================\n",
            "\n",
            "Dataset & Setup\n",
            "---------------\n",
            "We use the pre-split 10-class tomato leaf disease dataset `plantdiseasedataset10classessplit` with lab-style single-leaf images, 224x224 resizing, standard augmentations (flips, rotation, ColorJitter) for training, and ImageNet normalization for both train and test loaders. [file:2]\n",
            "\n",
            "ResNet50 Baseline (Week 2)\n",
            "--------------------------\n",
            "The Week-2 ResNet50 baseline, fine-tuned from ImageNet weights, achieved approximately 0.9955 test accuracy and 0.9946 macro F1 using the same train/test splits and augmentations. [file:1]\n",
            "\n",
            "EfficientNet-B0 (Week 3)\n",
            "------------------------\n",
            "We trained EfficientNet-B0 with Adam (lr=1e-3) and CosineAnnealingLR for 12 epochs on a T4 GPU, using the test set as validation to track best accuracy. The final model reached 0.9965 test accuracy and 0.9952 macro F1, which is higher the ResNet50 baseline by +0.0006 F1. [web:16]\n",
            "\n",
            "ResNet18 (Week 3)\n",
            "-----------------\n",
            "ResNet18, a lighter residual network (~11.18M trainable params), was trained for 10 epochs with the same optimizer and scheduler. It achieved 0.9938 test accuracy and 0.9929 macro F1, i.e., -0.0016 F1 relative to the ResNet50 baseline.\n",
            "\n",
            "Overall Comparison & Efficiency\n",
            "-------------------------------\n",
            "Across all models, EfficientNet-B0 achieved the highest macro F1 on the test set while staying within the ~3-hour T4 GPU budget using shared data loaders and short (10â€“12 epoch) fine-tuning schedules. EfficientNet-B0 provides a strong accuracyâ€“parameter trade-off compared to ResNet50, whereas ResNet18 is the most parameter-efficient option with still competitive performance. [web:7][web:9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Artifacts Checklist\n",
        "\n",
        "By the end of the notebook, the following key Weekâ€‘3 artifacts should exist\n",
        "under `BASE_DIR`:\n",
        "\n",
        "- `bestresnet50checkpoint.pth`  (from Week 2, reused) [file:1]  \n",
        "- `best_efficientnet.pth`       (created by `train_model` with `model_name=\"efficientnet\"`)  \n",
        "- `best_resnet18.pth`           (explicit save after training ResNet18)  \n",
        "- `resnet50_cm.png`, `efficientnet_b0_cm.png`, `resnet18_cm.png`  \n",
        "- `comparison_table.md`, `short_report.md`  \n",
        "\n",
        "You can now inspect the markdown files in Drive, or download them for\n",
        "inclusion in your final report.\n"
      ],
      "metadata": {
        "id": "ASDimKnkrMAv"
      }
    }
  ]
}